package com.example.controllers;

import com.example.data.DataAnalyzer;
import com.example.data.DataCleaner;
import com.example.data.DataLoader;
import com.example.data.FeatureEngineer;
import com.example.evaluation.ModelEvaluator;

import weka.classifiers.trees.RandomForest;
import weka.core.Instances;

//Main controller cho Data Mining Pipeline
//Qu·∫£n l√Ω to√†n b·ªô quy tr√¨nh t·ª´ preprocessing ƒë·∫øn model evaluation

public class MiningController {
    private final DataCleaner cleaner = new DataCleaner();
    private final DataAnalyzer analyzer = new DataAnalyzer();
    private final DataLoader loader = new DataLoader();
    private final FeatureEngineer engineer = new FeatureEngineer();
    private final ModelEvaluator evaluator = new ModelEvaluator();

    /*
    Ch·∫°y to√†n b·ªô pipeline: Preprocessing ‚Üí Training ‚Üí Evaluation 
    @param rawPath ƒê∆∞·ªùng d·∫´n file dataset g·ªëc (.csv ho·∫∑c .arff)
    @param reportPath ƒê∆∞·ªùng d·∫´n file b√°o c√°o k·∫øt qu·∫£
     @throws Exception L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω
     */
    public void runPipeline(String rawPath, String reportPath) throws Exception {
        printHeader("HEART DISEASE RISK PREDICTOR - DATA MINING PIPELINE");
        printSectionHeader("STEP 1: DATA PREPROCESSING");
        //Load Dataset
        System.out.println("\nLoading dataset...");
        Instances data = loader.loadDataset(rawPath);
        exploreDataset(data);
        //Handle Missing Values & Remove Duplicates
        System.out.println("\nCleaning data...");
        data = cleaner.cleanData(data);
        //Remove Outliers
        System.out.println("\nRemoving outliers...");
        data = cleaner.removeOutliers(data);
        //Feature Engineering
        System.out.println("\nEngineering features...");
        data = engineer.createFeatures(data);
        //Normalize Data
        System.out.println("\nNormalizing data...");
        data = cleaner.normalize(data);
        //Data Analysis
        System.out.println("\nAnalyzing dataset...");
        analyzer.analyzeData(data);
        //Feature Importance Analysis
        System.out.println("\nCalculating feature importance...");
        analyzer.featureImportance(data);
        //Save Preprocessed Data
        System.out.println("\nSaving preprocessed data...");
        String cleanedPath = "src/resources/data_cleaned.arff";
        loader.saveARFF(data, cleanedPath);

        System.out.println("\nSTEP 1 COMPLETED: Data preprocessing finished!");
        System.out.println("   Preprocessed data saved to: " + cleanedPath);
        printSectionHeader("STEP 2: J48 DECISION TREE - BASELINE MODEL");
        weka.classifiers.trees.J48 j48 = new weka.classifiers.trees.J48();
        j48.setConfidenceFactor(0.25f);
        j48.setMinNumObj(2);
        j48.setUnpruned(false);
        evaluator.evaluateModel(j48, data, reportPath);
        System.out.println("\nSTEP 2 COMPLETED: J48 baseline model evaluated!");
        printSectionHeader("STEP 3: RANDOM FOREST - IMPROVED MODEL");
        System.out.println("\nApplying SMOTE for class balancing...");
        Instances balancedData = cleaner.applySMOTE(data);
        //Feature Selection
        System.out.println("\nPerforming feature selection...");
        Instances selectedData = cleaner.selectFeatures(balancedData);
        //Save improved dataset
        String improvedPath = "src/resources/data_improved.arff";
        loader.saveARFF(selectedData, improvedPath);
        System.out.println("   Improved data saved to: " + improvedPath);
        
        // Train Random Forest
        RandomForest rf = new RandomForest();
        rf.setNumIterations(100);
        rf.setSeed(1);
        evaluator.evaluateModel(rf, data, reportPath);
        
        System.out.println("\n‚úÖ STEP 3 COMPLETED: Random Forest improved model evaluated!");
        
        // ========================================
        // STEP 4: MODEL COMPARISON
        // ========================================
        printSectionHeader("STEP 4: MODEL COMPARISON & FINAL REPORT");
        
        System.out.println("\nüìà Generating comparison report...");
        evaluator.compareModels(reportPath);
        
        // Final Summary
        printFinalSummary(reportPath);
    }
    
    /**
     * Explore dataset - In th√¥ng tin t·ªïng quan
     */
    private void exploreDataset(Instances data) {
        System.out.println("\n--- Dataset Overview ---");
        System.out.println("üìÅ Total instances: " + data.numInstances());
        System.out.println("üìä Total attributes: " + data.numAttributes());
        System.out.println("üéØ Class attribute: " + data.classAttribute().name());
        System.out.println("üìã Class values: " + data.classAttribute().numValues());
        
        System.out.println("\n--- Attributes List ---");
        for (int i = 0; i < Math.min(10, data.numAttributes()); i++) {
            String type = data.attribute(i).isNumeric() ? "Numeric" : "Nominal";
            System.out.printf("  %2d. %-20s [%s]\n", 
                i + 1, data.attribute(i).name(), type);
        }
        if (data.numAttributes() > 10) {
            System.out.println("  ... and " + (data.numAttributes() - 10) + " more");
        }
    }
    
    /**
     * Print header cho to√†n b·ªô pipeline
     */
    private void printHeader(String title) {
        System.out.println("\n" + "=".repeat(60));
        System.out.println("  " + title);
        System.out.println("=".repeat(60));
    }
    
    /**
     * Print header cho t·ª´ng section
     */
    private void printSectionHeader(String title) {
        System.out.println("\n\n" + "‚ïê".repeat(60));
        System.out.println("  " + title);
        System.out.println("‚ïê".repeat(60));
    }
    
    /**
     * Print final summary
     */
    private void printFinalSummary(String reportPath) {
        System.out.println("\n" + "=".repeat(60));
        System.out.println("  üéâ PIPELINE COMPLETED SUCCESSFULLY!");
        System.out.println("=".repeat(60));
        System.out.println("\nüìÑ Reports generated:");
        System.out.println("   ‚Ä¢ Evaluation report: " + reportPath);
        System.out.println("   ‚Ä¢ Preprocessed data: src/resources/data_cleaned.arff");
        System.out.println("   ‚Ä¢ Improved data: src/resources/data_improved.arff");
        System.out.println("\nüìä Models trained:");
        System.out.println("   ‚Ä¢ J48 Decision Tree (Baseline)");
        System.out.println("   ‚Ä¢ Random Forest + SMOTE + Feature Selection (Improved)");
        System.out.println("\nüí° Next steps:");
        System.out.println("   1. Review evaluation_report.txt for detailed metrics");
        System.out.println("   2. Analyze confusion matrices and ROC curves");
        System.out.println("   3. Compare model performance for clinical deployment");
        System.out.println("\n" + "=".repeat(60) + "\n");
    }
    
    /**
     * Main method ƒë·ªÉ ch·∫°y pipeline
     */
    public static void main(String[] args) {
        try {
            MiningController controller = new MiningController();
            
            // ƒê∆∞·ªùng d·∫´n files
            String rawDataPath = "src/resources/heart_disease.csv";
            String reportPath = "src/resources/evaluation_report.txt";
            
            // Ch·∫°y pipeline
            controller.runPipeline(rawDataPath, reportPath);
            
        } catch (Exception e) {
            System.err.println("\n‚ùå ERROR: Pipeline failed!");
            System.err.println("Error message: " + e.getMessage());
            e.printStackTrace();
        }
    }
}